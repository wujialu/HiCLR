{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare USPTO-sm and USPTO-lg for template-relevance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not allready in repo download temprel-fortunato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import requests \n",
    "\n",
    "def download_temprel_repo(save_path, chunk_size=128):\n",
    "    \"downloads the template-relevance master branch\"\n",
    "    url = \"https://gitlab.com/mefortunato/template-relevance/-/archive/master/template-relevance-master.zip\"\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def unzip(path):\n",
    "    \"unzips a file given a path\"\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path.replace('.zip',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/temprel-fortunato.zip'\n",
    "download_temprel_repo(path)\n",
    "unzip(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install template-relevance from fortunato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///publicwork/seidl/testing_projects/release/mhn-react/data/temprel-fortunato/template-relevance-master\n",
      "Installing collected packages: temprel\n",
      "  Attempting uninstall: temprel\n",
      "    Found existing installation: temprel 1.0\n",
      "    Uninstalling temprel-1.0:\n",
      "      Successfully uninstalled temprel-1.0\n",
      "  Running setup.py develop for temprel\n",
      "Successfully installed temprel\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/temprel-fortunato/template-relevance-master/\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also make sure you have the right rdchiral version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -e \"git://github.com/connorcoley/rdchiral.git#egg=rdchiral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# code from fortunato\n",
    "# could also import  from temprel.data.download import get_uspto_50k but slightly altered ;)\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def download_file(url, output_path=None):\n",
    "    if not output_path:\n",
    "        output_path = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "def get_uspto_480k():\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    if not os.path.exists('data/raw'):\n",
    "        os.mkdir('data/raw')\n",
    "    os.chdir('data/raw')\n",
    "    download_file(\n",
    "        'https://github.com/connorcoley/rexgen_direct/raw/master/rexgen_direct/data/train.txt.tar.gz',\n",
    "        'train.txt.tar.gz'\n",
    "    )\n",
    "    subprocess.run(['tar', 'zxf', 'train.txt.tar.gz'])\n",
    "    download_file(\n",
    "        'https://github.com/connorcoley/rexgen_direct/raw/master/rexgen_direct/data/valid.txt.tar.gz',\n",
    "        'valid.txt.tar.gz'\n",
    "    )\n",
    "    subprocess.run(['tar', 'zxf', 'valid.txt.tar.gz'])\n",
    "    download_file(\n",
    "        'https://github.com/connorcoley/rexgen_direct/raw/master/rexgen_direct/data/test.txt.tar.gz',\n",
    "        'test.txt.tar.gz'\n",
    "    )\n",
    "    subprocess.run(['tar', 'zxf', 'test.txt.tar.gz'])\n",
    "\n",
    "    with open('train.txt') as f:\n",
    "        train = [\n",
    "            {\n",
    "                'reaction_smiles': line.strip(), \n",
    "                'split': 'train'\n",
    "            }\n",
    "            for line in f.readlines()\n",
    "        ]\n",
    "    with open('valid.txt') as f:\n",
    "        valid = [\n",
    "            {\n",
    "                'reaction_smiles': line.strip(), \n",
    "                'split': 'valid'\n",
    "            }\n",
    "            for line in f.readlines()\n",
    "        ]\n",
    "    with open('test.txt') as f:\n",
    "        test = [\n",
    "            {\n",
    "                'reaction_smiles': line.strip(), \n",
    "                'split': 'test'\n",
    "            }\n",
    "            for line in f.readlines()\n",
    "        ]\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(train),\n",
    "        pd.DataFrame(valid),\n",
    "        pd.DataFrame(test)\n",
    "    ]).reset_index()\n",
    "    df.to_json('uspto_lg_reactions.json.gz', compression='gzip')\n",
    "    os.chdir('..')\n",
    "    os.chdir('..')\n",
    "    return df\n",
    "\n",
    "def get_uspto_50k():\n",
    "    '''\n",
    "    get SI from:\n",
    "    Nadine Schneider; Daniel M. Lowe; Roger A. Sayle; Gregory A. Landrum. J. Chem. Inf. Model.201555139-53\n",
    "    '''\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    if not os.path.exists('data/raw'):\n",
    "        os.mkdir('data/raw')\n",
    "    os.chdir('data/raw')\n",
    "    subprocess.run(['wget', 'https://pubs.acs.org/doi/suppl/10.1021/ci5006614/suppl_file/ci5006614_si_002.zip'])\n",
    "    subprocess.run(['unzip', '-o', 'ci5006614_si_002.zip'])\n",
    "    data = []\n",
    "    with gzip.open('ChemReactionClassification/data/training_test_set_patent_data.pkl.gz') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                data.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    reaction_smiles = [d[0] for d in data]\n",
    "    reaction_reference = [d[1] for d in data]\n",
    "    reaction_class = [d[2] for d in data]\n",
    "    df = pd.DataFrame()\n",
    "    df['reaction_smiles'] = reaction_smiles\n",
    "    df['reaction_reference'] = reaction_reference\n",
    "    df['reaction_class'] = reaction_class\n",
    "    df.to_json('uspto_sm_reactions.json.gz', compression='gzip')\n",
    "    os.chdir('..')\n",
    "    os.chdir('..')\n",
    "    return df\n",
    "\n",
    "def get_uspto_golden():\n",
    "    \"\"\" get uspto golden and convert it to smiles dataframe from \n",
    "    Lin, Arkadii; Dyubankova, Natalia; Madzhidov, Timur; Nugmanov, Ramil; \n",
    "    Rakhimbekova, Assima; Ibragimova, Zarina; Akhmetshin, Tagir; Gimadiev, \n",
    "    Timur; Suleymanov, Rail; Verhoeven, Jonas; Wegner, JÃ¶rg Kurt; \n",
    "    Ceulemans, Hugo; Varnek, Alexandre (2020): \n",
    "    Atom-to-Atom Mapping: A Benchmarking Study of Popular Mapping Algorithms and Consensus Strategies. \n",
    "    ChemRxiv. Preprint. https://doi.org/10.26434/chemrxiv.13012679.v1\n",
    "    \"\"\"\n",
    "    if os.path.exists('data/raw/uspto_golden.json.gz'):\n",
    "        print('loading precomputed')\n",
    "        return pd.read_json('data/raw/uspto_golden.json.gz', compression='gzip')\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    if not os.path.exists('data/raw'):\n",
    "        os.mkdir('data/raw')\n",
    "    os.chdir('data/raw')\n",
    "    subprocess.run(['wget', 'https://github.com/Laboratoire-de-Chemoinformatique/Reaction_Data_Cleaning/raw/master/data/golden_dataset.zip'])\n",
    "    subprocess.run(['unzip', '-o', 'golden_dataset.zip']) #return golden_dataset.rdf\n",
    "    \n",
    "    from CGRtools.files import RDFRead\n",
    "    import CGRtools\n",
    "    from rdkit.Chem import AllChem\n",
    "    def cgr2rxnsmiles(cgr_rx):    \n",
    "        smiles_rx = '.'.join([AllChem.MolToSmiles(CGRtools.to_rdkit_molecule(m)) for m in cgr_rx.reactants])\n",
    "        smiles_rx += '>>'+'.'.join([AllChem.MolToSmiles(CGRtools.to_rdkit_molecule(m)) for m in cgr_rx.products])\n",
    "        return smiles_rx\n",
    "\n",
    "    data = {}\n",
    "    input_file = 'golden_dataset.rdf'\n",
    "    do_basic_standardization=True\n",
    "    print('reading and converting the rdf-file')\n",
    "    with RDFRead(input_file) as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    r = next(f)\n",
    "                    key = r.meta['Reaction_ID']\n",
    "                    if do_basic_standardization:\n",
    "                        r.thiele()\n",
    "                        r.standardize()\n",
    "                    data[key] = cgr2rxnsmiles(r)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "    \n",
    "    print('saving as a dataframe to data/uspto_golden.json.gz')\n",
    "    df = pd.DataFrame([data],index=['reaction_smiles']).T\n",
    "    df['reaction_reference'] = df.index\n",
    "    df.index = range(len(df)) #reindex\n",
    "    df.to_json('uspto_golden.json.gz', compression='gzip')\n",
    "    \n",
    "    os.chdir('..')\n",
    "    os.chdir('..')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the scripts form temprel\n",
    "for more details see his documentation [readme](https://gitlab.com/mefortunato/template-relevance#step-1-extract-templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an alternative is to run the script\n",
    "```ssh\n",
    "python data/temprel-fortunato/template-relevance-master/bin/get_uspto_50k.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python data/temprel-fortunato/template-relevance-master/bin/process.py --reactions data/raw/uspto_sm_reactions.json.gz --output-prefix uspto_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this code ;)\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from temprel.templates.extract import process_for_training, process_for_askcos, templates_from_reactions\n",
    "\n",
    "reactions_sm = get_uspto_50k() ## get the dataset\n",
    "templates_sm = templates_from_reactions(reactions_sm, nproc=50)\n",
    "templates_sm.to_json('data/processed/uspto_sm_templates.df.json.gz', compression='gzip') \n",
    "process_for_training(templates_sm, output_prefix='data/processed/uspto_sm_', calc_split='stratified')\n",
    "# standardize templates\n",
    "process_for_askcos(templates_sm, template_set_name='uspto_sm_', output_prefix='data/processed/uspto_sm_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the applicability matrix.. this will also take some time\n",
    "if needed install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c anaconda mpi4py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#either running it multiprocessing or single (next one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed [read]: 0.2093029022216797\n",
      "elapsed [scatter]: 0.015007734298706055\n",
      "elapsed [convert]: 0.046427011489868164\n",
      "elapsed [appl]: 9.622829675674438\n",
      "elapsed [gather]: 0.002859830856323242\n",
      "elapsed [save]: 0.1777646541595459\n",
      "elapsed [scatter]: 0.006601095199584961\n",
      "elapsed [convert]: 0.017879962921142578\n",
      "elapsed [appl]: 7.5379109382629395\n",
      "elapsed [gather]: 0.001821279525756836\n",
      "elapsed [save]: 0.13137435913085938\n",
      "elapsed [scatter]: 0.06669163703918457\n",
      "elapsed [convert]: 0.11849093437194824\n",
      "elapsed [appl]: 54.74601745605469\n",
      "elapsed [gather]: 0.022233247756958008\n",
      "elapsed [save]: 0.8161919116973877\n"
     ]
    }
   ],
   "source": [
    "!mpirun -n 30 python data/temprel-fortunato/template-relevance-master/bin/calculate_applicabilty.py \\\n",
    "--templates data/processed/uspto_sm_retro.templates.uspto_sm_.json.gz \\\n",
    "--train-smiles data/processed/uspto_sm_train.input.smiles.npy \\\n",
    "--valid-smiles data/processed/uspto_sm_valid.input.smiles.npy \\\n",
    "--test-smiles data/processed/uspto_sm_test.input.smiles.npy \\\n",
    "--output-prefix data/processed/uspto_sm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhnreact.data import load_templates\n",
    "# load in the templates\n",
    "t = load_templates('sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate applicability via substructureuniquearch -- fast way\n",
    "import numpy as np\n",
    "from mhnreact.molutils import smarts2appl\n",
    "\n",
    "prods = np.array(templates_sm.products)\n",
    "template_product_smarts = np.array([t[ti].split('>>')[-1] for ti in t])\n",
    "%time appl = smarts2appl(prods, template_product_smarts, njobs=60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's do the same for the large dataset\n",
    "this might take a while ;) grab a coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from temprel.templates.extract import process_for_training, process_for_askcos, templates_from_reactions\n",
    "\n",
    "reactions_lg = get_uspto_480k() ## get the dataset\n",
    "reactions_lg.drop(columns='index', inplace=True) #correcting for a lg specific bug\n",
    "templates_lg = templates_from_reactions(reactions_lg, nproc=100)\n",
    "templates_lg.to_json('data/processed/uspto_lg_templates.df.json.gz', compression='gzip') \n",
    "process_for_training(templates_lg, output_prefix='data/processed/uspto_lg_', calc_split='stratified')\n",
    "process_for_askcos(templates_lg, template_set_name='uspto_lg_', output_prefix='data/processed/uspto_lg_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or run the script ;) --> won't work --> error with index col\n",
    "#!python data/temprel-fortunato/template-relevance-master/bin/process.py --reactions data/raw/uspto_lg_reactions.json.gz --nproc 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=$(pwd)/data/temprel-fortunato/template-relevance-master/bin:${PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was used by fotrunato\n",
    "#!mpirun -n 60 --oversubscribe python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun -n 50 python data/temprel-fortunato/template-relevance-master/bin/calculate_applicabilty.py \\\n",
    "--templates data/processed/uspto_lg_retro.templates.uspto_lg_.json.gz \\\n",
    "--train-smiles data/processed/uspto_lg_train.input.smiles.npy \\\n",
    "--valid-smiles data/processed/uspto_lg_valid.input.smiles.npy \\\n",
    "--test-smiles data/processed/uspto_lg_test.input.smiles.npy \\\n",
    "--output-prefix data/processed/uspto_lg_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally the data can be loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uspto_sm_test.appl_matrix.npz',\n",
       " 'uspto_sm_reactions.uspto_sm_.json.gz',\n",
       " 'uspto_sm_historian.uspto_sm_.json.gz',\n",
       " 'uspto_sm_train.input.smiles.npy',\n",
       " 'uspto_sm_valid.input.smiles.npy',\n",
       " 'uspto_sm_retro.templates.uspto_sm_.json.gz',\n",
       " 'uspto_sm_templates.df.json.gz',\n",
       " 'uspto_sm_test.labels.classes.npy',\n",
       " 'uspto_sm_valid.appl_matrix.npz',\n",
       " 'uspto_sm_valid.labels.classes.npy',\n",
       " 'uspto_sm_train.appl_matrix.npz',\n",
       " 'uspto_sm_train.labels.classes.npy',\n",
       " 'uspto_sm_test.input.smiles.npy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from mhnreact.data import *\n",
    "os.listdir('data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 29816 samples ( 9161 max label)\n",
      "valid 4482 samples ( 9157 max label)\n",
      "test 5959 samples ( 9145 max label)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "X, y = load_USPTO('sm',is_appl_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CH3:17][O:18][CH:2]([CH3:3])[c:4]1[n:5][c:6]2[cH:12][cH:11][cH:10][cH:9][c:7]2[nH:8]1'],\n",
       " 2962)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['train'][0], y['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 29816 samples ( 9162 max label)\n",
      "valid 4482 samples ( 9162 max label)\n",
      "test 5959 samples ( 9162 max label)\n"
     ]
    }
   ],
   "source": [
    "# load in the applicability matrix\n",
    "X, y_appl = load_USPTO('sm',is_appl_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the templates\n",
    "t = load_templates('sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
