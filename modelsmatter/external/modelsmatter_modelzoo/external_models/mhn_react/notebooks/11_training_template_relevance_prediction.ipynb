{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# template relevance prediction training\n",
    "for saving the model to ```./data/model/``` add ```--save_model True```\n",
    "\n",
    "for further details call ```python -m mhnreact.train -h```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train DNN for template relevance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded with 0\n",
      "train 29816 samples ( 9161 max label)\n",
      "valid 4482 samples ( 9157 max label)\n",
      "test 5959 samples ( 9145 max label)\n",
      "[610, 1699, 287, 180, 143, 105, 70, 48, 124, 86, 68, 2539, 1648]\n",
      "{'fingerprint_type': 'morgan', 'template_fp_type': 'rdk', 'num_templates': 9162, 'fp_size': 4096, 'fp_radius': 2, 'device': 'cuda:1', 'batch_size': 256, 'pooling_operation_state_embedding': 'mean', 'pooling_operation_head': 'max', 'dropout': 0.15, 'lr': 0.0005, 'optimizer': 'Adam', 'activation_function': 'ReLU', 'verbose': False, 'hopf_input_size': 4096, 'hopf_output_size': None, 'hopf_num_heads': 1, 'hopf_asso_dim': 2048, 'hopf_association_activation': 'None', 'hopf_beta': 0.05, 'norm_input': False, 'norm_asso': False, 'hopf_n_layers': 1, 'mol_encoder_layers': 1, 'temp_encoder_layers': 1, 'encoder_af': 'ReLU', 'normalize': True, 'norm_affine': True, 'hopf_pooling_operation_head': 'mean'}\n",
      "117it [00:02, 47.77it/s]\n",
      " 0 -- train_loss: 6.897, loss_valid: 5.957, val_t1acc: 0.240, val_t100acc: 0.567\n",
      "117it [00:02, 48.01it/s]\n",
      " 1 -- train_loss: 4.298, loss_valid: 4.945, val_t1acc: 0.317, val_t100acc: 0.703\n",
      "117it [00:02, 48.17it/s]\n",
      " 2 -- train_loss: 2.836, loss_valid: 4.391, val_t1acc: 0.380, val_t100acc: 0.766\n",
      "117it [00:02, 47.86it/s]\n",
      " 3 -- train_loss: 1.671, loss_valid: 4.200, val_t1acc: 0.407, val_t100acc: 0.786\n",
      "117it [00:02, 47.91it/s]\n",
      " 4 -- train_loss: 0.818, loss_valid: 4.217, val_t1acc: 0.419, val_t100acc: 0.788\n",
      "117it [00:02, 47.89it/s]\n",
      " 5 -- train_loss: 0.429, loss_valid: 4.302, val_t1acc: 0.420, val_t100acc: 0.792\n",
      "117it [00:02, 47.85it/s]\n",
      " 6 -- train_loss: 0.277, loss_valid: 4.421, val_t1acc: 0.420, val_t100acc: 0.792\n",
      "117it [00:02, 48.07it/s]\n",
      " 7 -- train_loss: 0.196, loss_valid: 4.528, val_t1acc: 0.420, val_t100acc: 0.792\n",
      "117it [00:02, 48.12it/s]\n",
      " 8 -- train_loss: 0.153, loss_valid: 4.582, val_t1acc: 0.424, val_t100acc: 0.791\n",
      "117it [00:02, 48.32it/s]\n",
      " 9 -- train_loss: 0.123, loss_valid: 4.656, val_t1acc: 0.426, val_t100acc: 0.792\n",
      "saving predictions to ./data/preds/USPTO_sm_test_segler_rerun_1632299812.npy\n",
      "model saved to data/model/USPTO_sm_segler_valloss4.656_rerun_1632299812.pt\n",
      "4.19974672794342\n"
     ]
    }
   ],
   "source": [
    "#sm_DNN_no_test\n",
    "!python -m mhnreact.train --device cuda:1 --dataset_type sm --exp_name rerun --model_type segler \\\n",
    "--pretrain_epochs 0 --epochs 10 --hopf_asso_dim 2048 --fp_type morgan --fp_size 4096 --dropout 0.15 \\\n",
    "--lr 0.0005 --mol_encoder_layers 1 --batch_size 256 --save_preds True --save_model True \\\n",
    "--seed 0 --fp_radius 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretraining on applicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded with 0\n",
      "train 29816 samples ( 9161 max label)\n",
      "valid 4482 samples ( 9157 max label)\n",
      "test 5959 samples ( 9145 max label)\n",
      "[610, 1699, 287, 180, 143, 105, 70, 48, 124, 86, 68, 2539, 1648]\n",
      "{'fingerprint_type': 'morgan', 'template_fp_type': 'rdk', 'num_templates': 9162, 'fp_size': 4096, 'fp_radius': 2, 'device': 'cuda:1', 'batch_size': 256, 'pooling_operation_state_embedding': 'mean', 'pooling_operation_head': 'max', 'dropout': 0.15, 'lr': 0.0005, 'optimizer': 'Adam', 'activation_function': 'ReLU', 'verbose': False, 'hopf_input_size': 4096, 'hopf_output_size': None, 'hopf_num_heads': 1, 'hopf_asso_dim': 2048, 'hopf_association_activation': 'None', 'hopf_beta': 0.05, 'norm_input': False, 'norm_asso': False, 'hopf_n_layers': 1, 'mol_encoder_layers': 1, 'temp_encoder_layers': 1, 'encoder_af': 'ReLU', 'normalize': True, 'norm_affine': True, 'hopf_pooling_operation_head': 'mean'}\n",
      "pretraining on applicability-matrix -- loading the matrix\n",
      "train 29816 samples ( 9162 max label)\n",
      "valid 4482 samples ( 9162 max label)\n",
      "test 5959 samples ( 9162 max label)\n",
      "pre-training (BCE-loss)\n",
      "117it [00:05, 22.39it/s]\n",
      " 0 -- train_loss: 0.094, loss_valid: 0.042, train_acc: 0.99024\n",
      "117it [00:05, 22.41it/s]\n",
      " 1 -- train_loss: 0.040, loss_valid: 0.040, train_acc: 0.99024\n",
      "117it [00:05, 22.40it/s]\n",
      " 2 -- train_loss: 0.039, loss_valid: 0.040, train_acc: 0.99024\n",
      "117it [00:05, 22.51it/s]\n",
      " 3 -- train_loss: 0.038, loss_valid: 0.039, train_acc: 0.99024\n",
      "117it [00:05, 22.52it/s]\n",
      " 4 -- train_loss: 0.038, loss_valid: 0.039, train_acc: 0.99024\n",
      "117it [00:05, 22.57it/s]\n",
      " 5 -- train_loss: 0.038, loss_valid: 0.039, train_acc: 0.99024\n",
      "117it [00:05, 22.44it/s]\n",
      " 6 -- train_loss: 0.037, loss_valid: 0.040, train_acc: 0.99015\n",
      "117it [00:05, 22.55it/s]\n",
      " 7 -- train_loss: 0.037, loss_valid: 0.040, train_acc: 0.99014\n",
      "117it [00:05, 22.55it/s]\n",
      " 8 -- train_loss: 0.036, loss_valid: 0.040, train_acc: 0.99011\n",
      "117it [00:05, 22.53it/s]\n",
      " 9 -- train_loss: 0.036, loss_valid: 0.040, train_acc: 0.99004\n",
      "117it [00:05, 22.51it/s]\n",
      "10 -- train_loss: 0.035, loss_valid: 0.041, train_acc: 0.99001\n",
      "117it [00:05, 22.47it/s]\n",
      "11 -- train_loss: 0.035, loss_valid: 0.041, train_acc: 0.99003\n",
      "117it [00:05, 22.48it/s]\n",
      "12 -- train_loss: 0.034, loss_valid: 0.042, train_acc: 0.98983\n",
      "117it [00:05, 22.58it/s]\n",
      "13 -- train_loss: 0.034, loss_valid: 0.042, train_acc: 0.98976\n",
      "117it [00:05, 22.56it/s]\n",
      "14 -- train_loss: 0.033, loss_valid: 0.042, train_acc: 0.98975\n",
      "117it [00:05, 22.50it/s]\n",
      "15 -- train_loss: 0.033, loss_valid: 0.043, train_acc: 0.98972\n",
      "117it [00:05, 22.40it/s]\n",
      "16 -- train_loss: 0.032, loss_valid: 0.043, train_acc: 0.98960\n",
      "117it [00:05, 22.48it/s]\n",
      "17 -- train_loss: 0.032, loss_valid: 0.044, train_acc: 0.98949\n",
      "117it [00:05, 22.45it/s]\n",
      "18 -- train_loss: 0.031, loss_valid: 0.044, train_acc: 0.98946\n",
      "117it [00:05, 22.52it/s]\n",
      "19 -- train_loss: 0.031, loss_valid: 0.044, train_acc: 0.98944\n",
      "117it [00:05, 22.52it/s]\n",
      "20 -- train_loss: 0.030, loss_valid: 0.045, train_acc: 0.98935\n",
      "117it [00:05, 22.45it/s]\n",
      "21 -- train_loss: 0.030, loss_valid: 0.045, train_acc: 0.98934\n",
      "117it [00:05, 22.48it/s]\n",
      "22 -- train_loss: 0.029, loss_valid: 0.046, train_acc: 0.98921\n",
      "117it [00:05, 22.47it/s]\n",
      "23 -- train_loss: 0.029, loss_valid: 0.046, train_acc: 0.98904\n",
      "117it [00:05, 22.43it/s]\n",
      "24 -- train_loss: 0.029, loss_valid: 0.047, train_acc: 0.98922\n",
      "117it [00:02, 47.88it/s]\n",
      " 0 -- train_loss: 5.154, loss_valid: 4.276, val_t1acc: 0.369, val_t100acc: 0.756\n",
      "117it [00:02, 48.02it/s]\n",
      " 1 -- train_loss: 1.529, loss_valid: 3.946, val_t1acc: 0.418, val_t100acc: 0.805\n",
      "117it [00:02, 48.17it/s]\n",
      " 2 -- train_loss: 0.439, loss_valid: 4.059, val_t1acc: 0.417, val_t100acc: 0.804\n",
      "117it [00:02, 47.74it/s]\n",
      " 3 -- train_loss: 0.214, loss_valid: 4.160, val_t1acc: 0.425, val_t100acc: 0.804\n",
      "117it [00:02, 47.94it/s]\n",
      " 4 -- train_loss: 0.147, loss_valid: 4.227, val_t1acc: 0.425, val_t100acc: 0.803\n",
      "117it [00:02, 48.18it/s]\n",
      " 5 -- train_loss: 0.110, loss_valid: 4.272, val_t1acc: 0.422, val_t100acc: 0.805\n",
      "117it [00:02, 47.79it/s]\n",
      " 6 -- train_loss: 0.091, loss_valid: 4.350, val_t1acc: 0.420, val_t100acc: 0.803\n",
      "117it [00:02, 48.11it/s]\n",
      " 7 -- train_loss: 0.080, loss_valid: 4.360, val_t1acc: 0.425, val_t100acc: 0.803\n",
      "117it [00:02, 48.32it/s]\n",
      " 8 -- train_loss: 0.069, loss_valid: 4.425, val_t1acc: 0.422, val_t100acc: 0.803\n",
      "117it [00:02, 48.22it/s]\n",
      " 9 -- train_loss: 0.062, loss_valid: 4.404, val_t1acc: 0.423, val_t100acc: 0.804\n",
      "saving predictions to ./data/preds/USPTO_sm_test_fortunato_rerun_1632299982.npy\n",
      "model saved to data/model/USPTO_sm_fortunato_valloss4.404_rerun_1632299982.pt\n",
      "3.945611251725091\n"
     ]
    }
   ],
   "source": [
    "#sm_DNN_yes_test\n",
    "!python -m mhnreact.train --device cuda:1 --dataset_type sm --exp_name rerun \\\n",
    "--model_type fortunato --pretrain_epochs 25 --epochs 10 --hopf_asso_dim 2048 \\\n",
    "--fp_type morgan --fp_size 4096 --dropout 0.15 --lr 0.0005 \\\n",
    "--mol_encoder_layers 1 --batch_size 256 --save_preds True --save_model True \\\n",
    "--exp_name=rerun --seed 0 --fp_radius 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train MHN for template relevance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded with 0\n",
      "train 29816 samples ( 9161 max label)\n",
      "valid 4482 samples ( 9157 max label)\n",
      "test 5959 samples ( 9145 max label)\n",
      "[610, 1699, 287, 180, 143, 105, 70, 48, 124, 86, 68, 2539, 1648]\n",
      "{'fingerprint_type': 'morgan', 'template_fp_type': 'rdk', 'num_templates': 9162, 'fp_size': 4096, 'fp_radius': 2, 'device': 'cuda:1', 'batch_size': 1024, 'pooling_operation_state_embedding': 'mean', 'pooling_operation_head': 'max', 'dropout': 0.2, 'lr': 0.001, 'optimizer': 'Adam', 'activation_function': 'ReLU', 'verbose': False, 'hopf_input_size': 4096, 'hopf_output_size': None, 'hopf_num_heads': 1, 'hopf_asso_dim': 1024, 'hopf_association_activation': 'None', 'hopf_beta': 0.03, 'norm_input': False, 'norm_asso': True, 'hopf_n_layers': 1, 'mol_encoder_layers': 1, 'temp_encoder_layers': 1, 'encoder_af': 'ReLU', 'hopf_pooling_operation_head': 'mean'}\n",
      "loading tfp from file ./data/cache/templ_emb_4096_rdk2_9162_3083282594899452900587240289666014809109594710917180313564340596704210428539624892529205810214822540907625940879430504284296794943595967027539004835710563.npy\n",
      "Num of templates with added rand-vect of size 409 due to >=thresh (2): 1367\n",
      "(9162, 409) (9162,) 1367\n",
      "(9162, 4096) 9162\n",
      "adding template_matrix to params\n",
      "30it [00:02, 13.86it/s]\n",
      " 0 -- train_loss: 7.499, loss_valid: 5.818, val_t1acc: 0.129, val_t100acc: 0.654\n",
      "30it [00:02, 14.42it/s]\n",
      " 1 -- train_loss: 3.891, loss_valid: 3.622, val_t1acc: 0.339, val_t100acc: 0.866\n",
      "30it [00:02, 14.32it/s]\n",
      " 2 -- train_loss: 2.181, loss_valid: 3.097, val_t1acc: 0.397, val_t100acc: 0.908\n",
      "30it [00:02, 14.17it/s]\n",
      " 3 -- train_loss: 1.457, loss_valid: 2.941, val_t1acc: 0.419, val_t100acc: 0.917\n",
      "30it [00:02, 14.24it/s]\n",
      " 4 -- train_loss: 1.049, loss_valid: 2.884, val_t1acc: 0.429, val_t100acc: 0.921\n",
      "30it [00:02, 13.99it/s]\n",
      " 5 -- train_loss: 0.814, loss_valid: 2.881, val_t1acc: 0.436, val_t100acc: 0.923\n",
      "30it [00:02, 13.67it/s]\n",
      " 6 -- train_loss: 0.639, loss_valid: 2.902, val_t1acc: 0.436, val_t100acc: 0.920\n",
      "30it [00:02, 14.10it/s]\n",
      " 7 -- train_loss: 0.540, loss_valid: 2.923, val_t1acc: 0.436, val_t100acc: 0.918\n",
      "30it [00:02, 13.89it/s]\n",
      " 8 -- train_loss: 0.462, loss_valid: 2.952, val_t1acc: 0.440, val_t100acc: 0.918\n",
      "30it [00:02, 14.09it/s]\n",
      " 9 -- train_loss: 0.410, loss_valid: 2.974, val_t1acc: 0.444, val_t100acc: 0.915\n",
      "30it [00:02, 13.53it/s]\n",
      "10 -- train_loss: 0.363, loss_valid: 3.014, val_t1acc: 0.439, val_t100acc: 0.912\n",
      "30it [00:02, 13.84it/s]\n",
      "11 -- train_loss: 0.328, loss_valid: 3.079, val_t1acc: 0.437, val_t100acc: 0.911\n",
      "30it [00:02, 14.14it/s]\n",
      "12 -- train_loss: 0.305, loss_valid: 3.068, val_t1acc: 0.433, val_t100acc: 0.913\n",
      "30it [00:02, 13.98it/s]\n",
      "13 -- train_loss: 0.274, loss_valid: 3.104, val_t1acc: 0.439, val_t100acc: 0.911\n",
      "30it [00:02, 13.59it/s]\n",
      "14 -- train_loss: 0.263, loss_valid: 3.135, val_t1acc: 0.434, val_t100acc: 0.908\n",
      "30it [00:02, 14.02it/s]\n",
      "15 -- train_loss: 0.245, loss_valid: 3.138, val_t1acc: 0.436, val_t100acc: 0.905\n",
      "30it [00:02, 13.98it/s]\n",
      "16 -- train_loss: 0.242, loss_valid: 3.152, val_t1acc: 0.436, val_t100acc: 0.905\n",
      "30it [00:02, 13.90it/s]\n",
      "17 -- train_loss: 0.228, loss_valid: 3.170, val_t1acc: 0.436, val_t100acc: 0.904\n",
      "30it [00:02, 14.09it/s]\n",
      "18 -- train_loss: 0.216, loss_valid: 3.204, val_t1acc: 0.432, val_t100acc: 0.905\n",
      "30it [00:02, 13.99it/s]\n",
      "19 -- train_loss: 0.207, loss_valid: 3.237, val_t1acc: 0.433, val_t100acc: 0.900\n",
      "30it [00:02, 14.03it/s]\n",
      "20 -- train_loss: 0.202, loss_valid: 3.243, val_t1acc: 0.436, val_t100acc: 0.900\n",
      "30it [00:02, 13.91it/s]\n",
      "21 -- train_loss: 0.187, loss_valid: 3.248, val_t1acc: 0.436, val_t100acc: 0.900\n",
      "30it [00:02, 14.09it/s]\n",
      "22 -- train_loss: 0.185, loss_valid: 3.260, val_t1acc: 0.433, val_t100acc: 0.899\n",
      "30it [00:02, 13.92it/s]\n",
      "23 -- train_loss: 0.186, loss_valid: 3.293, val_t1acc: 0.437, val_t100acc: 0.895\n",
      "30it [00:02, 13.57it/s]\n",
      "24 -- train_loss: 0.182, loss_valid: 3.301, val_t1acc: 0.430, val_t100acc: 0.898\n",
      "30it [00:02, 13.86it/s]\n",
      "25 -- train_loss: 0.180, loss_valid: 3.288, val_t1acc: 0.431, val_t100acc: 0.894\n",
      "30it [00:02, 14.01it/s]\n",
      "26 -- train_loss: 0.179, loss_valid: 3.303, val_t1acc: 0.437, val_t100acc: 0.894\n",
      "30it [00:02, 13.97it/s]\n",
      "27 -- train_loss: 0.167, loss_valid: 3.329, val_t1acc: 0.433, val_t100acc: 0.891\n",
      "30it [00:02, 13.89it/s]\n",
      "28 -- train_loss: 0.163, loss_valid: 3.332, val_t1acc: 0.434, val_t100acc: 0.891\n",
      "30it [00:02, 14.04it/s]\n",
      "29 -- train_loss: 0.156, loss_valid: 3.333, val_t1acc: 0.434, val_t100acc: 0.895\n",
      "saving predictions to ./data/preds/USPTO_sm_test_mhn_rerun_1632318117.npy\n",
      "model saved to data/model/USPTO_sm_mhn_valloss3.333_rerun_1632318117.pt\n",
      "2.881380891799927\n"
     ]
    }
   ],
   "source": [
    "#sm_MHN_no_test\n",
    "!python -m mhnreact.train --batch_size=1024 --concat_rand_template_thresh=2 --dataset_type=sm \\\n",
    "--device=cuda:1 --dropout=0.2 --epochs=30 --exp_name=rerun --fp_size=4096 --fp_type=morgan --hopf_asso_dim=1024 \\\n",
    "--hopf_association_activation=None --hopf_beta=0.03 --temp_encoder_layers=1 --mol_encoder_layers=1 \\\n",
    "--norm_asso=True --norm_input=False --hopf_num_heads=1 --lr=0.001 --model_type=mhn --save_preds True --save_model True \\\n",
    "--exp_name=rerun --seed 0 --fp_radius 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation and loading in a trained model\n",
    "see ```notebooks/20_evaluation.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "fldr = './data/experiments/'\n",
    "dfs = []\n",
    "for fn in os.listdir(fldr):\n",
    "    if fn.split('.')[-1]=='tsv':\n",
    "        dfs.append(pd.read_csv(fldr+fn,sep='\\t'))\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = ['model_type', 'dataset_type', 'min_loss_valid', 'max_t1_acc_valid', 'max_t100_acc_valid']\n",
    "df[clms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
